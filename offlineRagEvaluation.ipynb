{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "833e1a61-44c0-400e-90bd-282c6f15d01a",
   "metadata": {},
   "source": [
    "# Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1740897a-1591-4f6e-8e58-6d1d3138c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents with id\n",
    "import json\n",
    "\n",
    "with open('documents-with-ids.json', 'rt') as f_in:\n",
    "    documents = json.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47d6264f-c078-4a15-90dd-c23106a88df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'Course - When will the course start?',\n",
       " 'course': 'data-engineering-zoomcamp',\n",
       " 'id': 'c02e79ef'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0d6ef24-13b4-4678-9ce4-143feac76a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth data set\n",
    "\n",
    "import pandas as pd\n",
    "df_ground_truth = pd.read_csv('ground-truth-data.csv')\n",
    "df_ground_truth = df_ground_truth[df_ground_truth.course == 'machine-learning-zoomcamp']\n",
    "ground_truth = df_ground_truth.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ec59ff2-7c3b-439f-9a4e-2ad83504f03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the intention behind the FAQ document for the Machine Learning Zoomcamp?',\n",
       " 'course': 'machine-learning-zoomcamp',\n",
       " 'document': '0227b872'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13bd84da-0a7d-492e-aeba-5c4c12434255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Index id to be able to retrieve answer using id\n",
    "doc_idx = {d['id']: d for d in documents}\n",
    "doc_idx['c02e79ef']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b00004d6-66ef-49f2-8094-b286a35ab5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_name = 'multi-qa-MiniLM-L6-cos-v1'\n",
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "65edfbd7-7577-4598-a9a8-d7bf7fa0a9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200') \n",
    "\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "            \"id\": {\"type\": \"keyword\"},\n",
    "            \"question_text_vector\": {\n",
    "                \"type\": \"dense_vector\",\n",
    "                \"dims\": 384,\n",
    "                \"index\": True,\n",
    "                \"similarity\": \"cosine\"\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.delete(index=index_name, ignore_unavailable=True)\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2b3c7f6-8dff-4925-9860-b47ab2835411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 948/948 [01:03<00:00, 15.03it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "for doc in tqdm(documents):\n",
    "    question = doc['question']\n",
    "    text = doc['text']\n",
    "    doc['question_text_vector'] = model.encode(question + ' ' + text)\n",
    "\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f235b971-9e69-4629-b70f-607d444a7c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search_knn(field, vector, course):\n",
    "    knn = {\n",
    "        \"field\": field,\n",
    "        \"query_vector\": vector,\n",
    "        \"k\": 5,\n",
    "        \"num_candidates\": 10000,\n",
    "        \"filter\": {\n",
    "            \"term\": {\n",
    "                \"course\": course\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_query = {\n",
    "        \"knn\": knn,\n",
    "        \"_source\": [\"text\", \"section\", \"question\", \"course\", \"id\"]\n",
    "    }\n",
    "\n",
    "    es_results = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in es_results['hits']['hits']:\n",
    "        result_docs.append(hit['_source'])\n",
    "\n",
    "    return result_docs\n",
    "\n",
    "def question_text_vector_knn(q):\n",
    "    question = q['question']\n",
    "    course = q['course']\n",
    "\n",
    "    v_q = model.encode(question)\n",
    "\n",
    "    return elastic_search_knn('question_text_vector', v_q, course)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1ba5898-481b-4235-9b14-88f49155e04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'What if I miss a session?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '5170565b'},\n",
       " {'text': 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Is it going to be live? When?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '39fda9f0'},\n",
       " {'text': '(Hrithik Kumar Advani)',\n",
       "  'section': '2. Machine Learning for Regression',\n",
       "  'question': 'Useful Resource for Missing Data Treatment\\nhttps://www.kaggle.com/code/parulpandey/a-guide-to-handling-missing-values-in-python/notebook',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '81b8e8d0'},\n",
       " {'text': \"Problem description\\nThe accuracy and the loss are both still the same or nearly the same while training.\\nSolution description\\nIn the homework, you should set class_mode='binary' while reading the data.\\nAlso, problem occurs when you choose the wrong optimizer, batch size, or learning rate\\nAdded by Ekaterina Kutovaia\",\n",
       "  'section': '8. Neural Networks and Deep Learning',\n",
       "  'question': 'The same accuracy on epochs',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '7d11d5ce'},\n",
       " {'text': \"Yes, it's possible. See the previous answer.\",\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'Will I get a certificate if I missed the midterm project?',\n",
       "  'course': 'machine-learning-zoomcamp',\n",
       "  'id': '1d644223'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_text_vector_knn(dict(\n",
    "    question='Are sessions recorded if I miss one?',\n",
    "    course='machine-learning-zoomcamp'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c64449e4-b1f1-43c8-b019-cc9a53c58608",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ec4d9c7-6c95-4417-b75c-51d30fe796f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt, model='gpt-4o'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ed47df1-3d1c-40c7-8820-03b74376ca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previously: rag(query: str) -> str\n",
    "def rag(query: dict, model='gpt-4o') -> str:\n",
    "    search_results = question_text_vector_knn(query)\n",
    "    prompt = build_prompt(query['question'], search_results)\n",
    "    answer = llm(prompt, model=model)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b05a31-4865-4fff-bffb-0b593fda0165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The intention behind the FAQ document for the Machine Learning Zoomcamp is to capture frequently asked technical questions. This approach was inspired by its successful implementation in their data engineering course.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(ground_truth[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d999a46a-98e3-410a-99d1-b0fad2dd4a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_idx['c02e79ef']['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c65aac5-7f31-46d3-8bf3-f1d3533a6eac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.16684134)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_original = \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\"\n",
    "answer_llm = 'The intention behind the FAQ document for the Machine Learning Zoomcamp is to capture frequently asked technical questions. This approach was previously used for their data engineering course and was found to be effective. The document serves as a resource for participants to find structured answers and guidance on technical queries related to the course.'\n",
    "\n",
    "v_llm = model.encode(answer_llm)\n",
    "v_original = model.encode(answer_original)\n",
    "\n",
    "v_llm.dot(v_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c252b9d3-d848-4eaa-8bd4-af6066f0681e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The intention behind the FAQ document for the Machine Learning Zoomcamp is to capture frequently asked technical questions, similar to what was done for the data engineering course. The aim is to provide a structured resource for course participants to reference.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using GPT 4o-mini\n",
    "\n",
    "rag(ground_truth[0], model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6f0cf0e-22fb-4750-aae6-c9ef1013c170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of the time it takes, lets use multi threading or parallel processing to generate answers for every questions\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "pool = ThreadPoolExecutor(max_workers=6) # Using 6 concurrent threads\n",
    "\n",
    "def map_progress(pool, seq, f):\n",
    "    results = []\n",
    "\n",
    "    with tqdm(total=len(seq)) as progress:\n",
    "        futures = []\n",
    "\n",
    "        for el in seq:\n",
    "            future = pool.submit(f, el)\n",
    "            future.add_done_callback(lambda p: progress.update())\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in futures:\n",
    "            result = future.result()\n",
    "            results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8329b102-6674-4a71-8876-28a8b569854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_record_4o_mini(rec):\n",
    "    model = 'gpt-4o-mini'\n",
    "    answer_llm = rag(rec, model=model)\n",
    "    \n",
    "    doc_id = rec['document']\n",
    "    original_doc = doc_idx[doc_id]\n",
    "    answer_original = original_doc['text']\n",
    "\n",
    "    return {\n",
    "        'answer_llm': answer_llm,\n",
    "        'answer_original': answer_original,\n",
    "        'document': doc_id,\n",
    "        'question': rec['question'],\n",
    "        'course': rec['course'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bae77f8c-8e36-4c70-a44d-50bd91374e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_gpt35 = map_progress(pool, ground_truth, process_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27ee9958-b51d-498b-92d0-07c5d924d30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': 'The intention behind the FAQ document for the Machine Learning Zoomcamp is to capture frequently asked technical questions. This approach was successfully implemented in their data engineering course, serving as a model for structuring questions and answers.',\n",
       " 'answer_original': 'Machine Learning Zoomcamp FAQ\\nThe purpose of this document is to capture frequently asked technical questions.\\nWe did this for our data engineering course and it worked quite well. Check this document for inspiration on how to structure your questions and answers:\\nData Engineering Zoomcamp FAQ\\nIn the course GitHub repository there’s a link. Here it is: https://airtable.com/shryxwLd0COOEaqXo\\nwork',\n",
       " 'document': '0227b872',\n",
       " 'question': 'What is the intention behind the FAQ document for the Machine Learning Zoomcamp?',\n",
       " 'course': 'machine-learning-zoomcamp'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_record_4o_mini(ground_truth[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c22eeaf9-de28-4381-a8eb-c2d6c8c9a9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt4o_mini = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8baf5a30-a155-4f73-a52d-c80105a98ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1838/1838 [46:59<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "for record in tqdm(ground_truth):\n",
    "    result = process_record_4o_mini(record)\n",
    "    results_gpt4o_mini.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f98f5b5-e8de-4d3c-873f-eb05d927aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gpt4o_mini = pd.DataFrame(results_gpt4o_mini)\n",
    "df_gpt4o_mini.to_csv('results_gpt4o_mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d324a9d-b9ef-401b-ad27-422bf90e8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_gpt4o_mini = df_gpt4o_mini.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5db60ba-ca65-4de6-a15f-dc4e00e80021",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = results_gpt4o_mini[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65867f6a-27cf-4b89-8590-bd6da842b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity(record):\n",
    "    answer_original = record['answer_original']\n",
    "    answer_llm = record['answer_llm']\n",
    "    \n",
    "    v_llm = model.encode(answer_llm)\n",
    "    v_original = model.encode(answer_original)\n",
    "    \n",
    "    return v_llm.dot(v_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ff9c3f9-147f-436c-a4c8-ea6c0ecd6ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 1838/1838 [02:39<00:00, 11.51it/s]\n"
     ]
    }
   ],
   "source": [
    "similarity = []\n",
    "\n",
    "for record in tqdm(results_gpt4o_mini):\n",
    "    sim = compute_similarity(record)\n",
    "    similarity.append(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2501ad45-72ff-4b4a-9960-6aac03ff8c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1838.000000\n",
       "mean        0.687138\n",
       "std         0.203796\n",
       "min        -0.142122\n",
       "25%         0.597458\n",
       "50%         0.734756\n",
       "75%         0.831409\n",
       "max         0.984759\n",
       "Name: cosine, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt4o_mini['cosine'] = similarity\n",
    "df_gpt4o_mini['cosine'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed38977-3d10-4db3-8453-f21ef245bba0",
   "metadata": {},
   "source": [
    "# LLM As A Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c5d97e4-f9fb-465f-9460-7fd0c87b9929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ground truth data set\n",
    "\n",
    "import pandas as pd\n",
    "df_gpt4o_mini = pd.read_csv('results_gpt4o_mini.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4a57af-7925-4f62-80d1-0bc4396a50eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_llm</th>\n",
       "      <th>answer_original</th>\n",
       "      <th>document</th>\n",
       "      <th>question</th>\n",
       "      <th>course</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The intention behind the FAQ document for the ...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>What is the intention behind the FAQ document ...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You can find a model for structuring questions...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where can I find a model for structuring quest...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>To find the sign-up link for the course, you c...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>Where should I look to find the sign-up link f...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The resource used to create frequently asked q...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>What resource was used to create frequently as...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You can access the sign-up link for the Machin...</td>\n",
       "      <td>Machine Learning Zoomcamp FAQ\\nThe purpose of ...</td>\n",
       "      <td>0227b872</td>\n",
       "      <td>How can I access the sign-up link for the Mach...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1833</th>\n",
       "      <td>You can list the Machine Learning Zoomcamp exp...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>What are some suggested titles I can use to li...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1834</th>\n",
       "      <td>It is not appropriate to list the Machine Lear...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Is it appropriate to list the Machine Learning...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>You can include your Machine Learning Zoomcamp...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>Which LinkedIn sections can I use to include m...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>To showcase your Machine Learning Zoomcamp pro...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>How can I showcase my Machine Learning Zoomcam...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>To highlight your progress from the Machine Le...</td>\n",
       "      <td>I’ve seen LinkedIn users list DataTalksClub as...</td>\n",
       "      <td>c6a22665</td>\n",
       "      <td>What can I do to highlight my progress from th...</td>\n",
       "      <td>machine-learning-zoomcamp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1838 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             answer_llm  \\\n",
       "0     The intention behind the FAQ document for the ...   \n",
       "1     You can find a model for structuring questions...   \n",
       "2     To find the sign-up link for the course, you c...   \n",
       "3     The resource used to create frequently asked q...   \n",
       "4     You can access the sign-up link for the Machin...   \n",
       "...                                                 ...   \n",
       "1833  You can list the Machine Learning Zoomcamp exp...   \n",
       "1834  It is not appropriate to list the Machine Lear...   \n",
       "1835  You can include your Machine Learning Zoomcamp...   \n",
       "1836  To showcase your Machine Learning Zoomcamp pro...   \n",
       "1837  To highlight your progress from the Machine Le...   \n",
       "\n",
       "                                        answer_original  document  \\\n",
       "0     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "1     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "2     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "3     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "4     Machine Learning Zoomcamp FAQ\\nThe purpose of ...  0227b872   \n",
       "...                                                 ...       ...   \n",
       "1833  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1834  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1835  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1836  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "1837  I’ve seen LinkedIn users list DataTalksClub as...  c6a22665   \n",
       "\n",
       "                                               question  \\\n",
       "0     What is the intention behind the FAQ document ...   \n",
       "1     Where can I find a model for structuring quest...   \n",
       "2     Where should I look to find the sign-up link f...   \n",
       "3     What resource was used to create frequently as...   \n",
       "4     How can I access the sign-up link for the Mach...   \n",
       "...                                                 ...   \n",
       "1833  What are some suggested titles I can use to li...   \n",
       "1834  Is it appropriate to list the Machine Learning...   \n",
       "1835  Which LinkedIn sections can I use to include m...   \n",
       "1836  How can I showcase my Machine Learning Zoomcam...   \n",
       "1837  What can I do to highlight my progress from th...   \n",
       "\n",
       "                         course  \n",
       "0     machine-learning-zoomcamp  \n",
       "1     machine-learning-zoomcamp  \n",
       "2     machine-learning-zoomcamp  \n",
       "3     machine-learning-zoomcamp  \n",
       "4     machine-learning-zoomcamp  \n",
       "...                         ...  \n",
       "1833  machine-learning-zoomcamp  \n",
       "1834  machine-learning-zoomcamp  \n",
       "1835  machine-learning-zoomcamp  \n",
       "1836  machine-learning-zoomcamp  \n",
       "1837  machine-learning-zoomcamp  \n",
       "\n",
       "[1838 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt4o_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55641a80-2b1e-433e-842c-d8fe7b3f8f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are randomly sampling just 150 records for this exercise as we know this takes a lot of time\n",
    "\n",
    "df_sample = df_gpt4o_mini.sample(n=150, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89fcbf47-5d91-4513-ada9-9613c516f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = df_sample.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb4d890-361d-4cd5-8c2d-74931787dc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer_llm': \"A key consideration when using DictVectorizer in Homework 3, Question 6, is to avoid fitting the DictVectorizer on the validation dataset. Doing so would give the model access to labels that it should not know, compromising the validity of the performance estimate on unseen data. Instead, you should fit the DictVectorizer on the training data and then only transform the validation and test sets. This ensures that the validation results reflect the model's performance on truly unseen data.\",\n",
       " 'answer_original': \"You need to use all features. and price for target. Don't include the average variable we created before.\\nIf you use DictVectorizer then make sure to use sparce=True to avoid convergence errors\\nI also used StandardScalar for numerical variable you can try running with or without this\\n(Peter Pan)\",\n",
       " 'document': '4a55c510',\n",
       " 'question': 'What is a key consideration when using DictVectorizer in Homework 3, Question 6?',\n",
       " 'course': 'machine-learning-zoomcamp'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record = samples[0]\n",
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9fbd5a-c675-492e-885b-0a0ee0a88d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two prompts because in case 1 we have all 3 requirements - Question, Original Answer and LLM Answer, but we will have another case where we dont always have the access to the original answer for which we generated questions which we may not have in production.\n",
    "\n",
    "prompt1_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
    "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
    "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Original Answer: {answer_original}\n",
    "Generated Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the original\n",
    "answer and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "prompt2_template = \"\"\"\n",
    "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
    "Your task is to analyze the relevance of the generated answer to the given question.\n",
    "Based on the relevance of the generated answer, you will classify it\n",
    "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
    "\n",
    "Here is the data for evaluation:\n",
    "\n",
    "Question: {question}\n",
    "Generated Answer: {answer_llm}\n",
    "\n",
    "Please analyze the content and context of the generated answer in relation to the question\n",
    "and provide your evaluation in parsable JSON without using code blocks:\n",
    "\n",
    "{{\n",
    "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
    "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
    "}}\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2671ae1b-7248-4525-84e5-37ad23b7917e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer compared to the original answer provided.\n",
      "Based on the relevance and similarity of the generated answer to the original answer, you will classify\n",
      "it as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Original Answer: You need to use all features. and price for target. Don't include the average variable we created before.\n",
      "If you use DictVectorizer then make sure to use sparce=True to avoid convergence errors\n",
      "I also used StandardScalar for numerical variable you can try running with or without this\n",
      "(Peter Pan)\n",
      "Generated Question: What is a key consideration when using DictVectorizer in Homework 3, Question 6?\n",
      "Generated Answer: A key consideration when using DictVectorizer in Homework 3, Question 6, is to avoid fitting the DictVectorizer on the validation dataset. Doing so would give the model access to labels that it should not know, compromising the validity of the performance estimate on unseen data. Instead, you should fit the DictVectorizer on the training data and then only transform the validation and test sets. This ensures that the validation results reflect the model's performance on truly unseen data.\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the original\n",
      "answer and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt1_template.format(**record)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b735c03f-5933-44ae-82b3-68ecd6d20a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def llm(prompt, model='gpt-4o'):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "440a2d5d-5221-42b2-9c47-bd41048bf180",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm(prompt, model='gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a11dcd2d-3ab0-4887-b65c-039fa50ce4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f4f382c-e1a3-42be-b445-130611bc889b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [03:51<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "evaluations = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt1_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c5cadc5-cc8e-4c87-9d18-13a10868dffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_evaluations = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations):\n",
    "    json_eval = json.loads(str_eval)\n",
    "    json_evaluations.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "190b0822-41c5-480d-bb2a-c7e3ca032b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations = pd.DataFrame(json_evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69d279df-acd5-4872-8088-9238e223fee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relevance\n",
       "RELEVANT           133\n",
       "PARTLY_RELEVANT     11\n",
       "NON_RELEVANT         6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations.Relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6289d42-fbf9-4786-b5ba-46227909dc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer discusses how to calculat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses a completely di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses general queries...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer addresses a different iss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>NON_RELEVANT</td>\n",
       "      <td>The generated answer does not address the cont...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Relevance                                        Explanation\n",
       "13   NON_RELEVANT  The generated answer discusses how to calculat...\n",
       "26   NON_RELEVANT  The generated answer does not address the spec...\n",
       "43   NON_RELEVANT  The generated answer addresses a completely di...\n",
       "54   NON_RELEVANT  The generated answer addresses general queries...\n",
       "83   NON_RELEVANT  The generated answer addresses a different iss...\n",
       "113  NON_RELEVANT  The generated answer does not address the cont..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations[df_evaluations.Relevance == 'NON_RELEVANT'] #.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d70f25b-2152-4171-8d61-825d2b8b5c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an expert evaluator for a Retrieval-Augmented Generation (RAG) system.\n",
      "Your task is to analyze the relevance of the generated answer to the given question.\n",
      "Based on the relevance of the generated answer, you will classify it\n",
      "as \"NON_RELEVANT\", \"PARTLY_RELEVANT\", or \"RELEVANT\".\n",
      "\n",
      "Here is the data for evaluation:\n",
      "\n",
      "Question: How do I configure TensorFlow for GPU on an Ubuntu system?\n",
      "Generated Answer: To configure TensorFlow for GPU on an Ubuntu system, you need to install CUDA and cuDNN. Here are the steps you can follow:\n",
      "\n",
      "1. Install Nvidia drivers. You can find them at [Nvidia's official site](https://www.nvidia.com/download/index.aspx).\n",
      "2. Install the CUDA toolkit (version 11.x.x) from the [CUDA Toolkit Archive](https://developer.nvidia.com/cuda-toolkit-archive).\n",
      "3. Download and install cuDNN from the [cuDNN download page](https://developer.nvidia.com/rdp/cudnn-download).\n",
      "4. Ensure that TensorFlow is installed, preferably using the `tensorflow-gpu` package.\n",
      "\n",
      "For a more detailed guide and useful resources, you can refer to this article: [Setting up TensorFlow with GPU support on Ubuntu](https://knowmledge.com/2023/12/07/ml-zoomcamp-2023-project/).\n",
      "\n",
      "Please analyze the content and context of the generated answer in relation to the question\n",
      "and provide your evaluation in parsable JSON without using code blocks:\n",
      "\n",
      "{\n",
      "  \"Relevance\": \"NON_RELEVANT\" | \"PARTLY_RELEVANT\" | \"RELEVANT\",\n",
      "  \"Explanation\": \"[Provide a brief explanation for your evaluation]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = prompt2_template.format(**record)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d7b3156-1696-47b2-b5b9-337ad043c404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Relevance\": \"RELEVANT\",\n",
      "  \"Explanation\": \"The generated answer directly addresses the question by providing specific steps to configure TensorFlow for GPU on an Ubuntu system. It includes essential components such as installing Nvidia drivers, CUDA, and cuDNN, which are crucial for GPU configuration. Additionally, it suggests using the `tensorflow-gpu` package and provides links for further resources, making it highly relevant to the user's query.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c0e02cc8-1e72-40a8-9c09-8aea91b470fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 150/150 [03:41<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "evaluations_2 = []\n",
    "\n",
    "for record in tqdm(samples):\n",
    "    prompt = prompt2_template.format(**record)\n",
    "    evaluation = llm(prompt, model='gpt-4o-mini')\n",
    "    evaluations_2.append(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "08b57b62-4bf8-42cf-bb0b-63ed9635507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_evaluations_2 = []\n",
    "\n",
    "for i, str_eval in enumerate(evaluations_2):\n",
    "    json_eval = json.loads(str_eval)\n",
    "    json_evaluations_2.append(json_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c5e9abb-3f17-4e43-bcc3-dbea827c64b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations_2 = pd.DataFrame(json_evaluations_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0a73ced9-30d6-486e-882f-e30f7e4b8522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Relevance\n",
       "RELEVANT           134\n",
       "PARTLY_RELEVANT     16\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_2.Relevance.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9d8be1c-3674-40b6-b1e4-a58981726cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Explanation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Relevance, Explanation]\n",
       "Index: []"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluations_2[df_evaluations_2.Relevance == 'NON_RELEVANT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e7a9ef7-e826-4d16-a4a9-8ca15c5cce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluations.to_csv('evaluations-aqa.csv', index=False)\n",
    "df_evaluations_2.to_csv('evaluations-qa.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965c40d3-6139-40e9-b25b-e86bf8364294",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
